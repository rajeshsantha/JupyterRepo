{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2b542ff-edc9-4e92-93ab-548d0ed6ff25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a Python function to count word occurrences in a large text file that doesn’t fit into memory.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \"Write a Python function to count word occurrences in a large text file that doesn’t fit into memory.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c910a7af-f5b0-461e-84c9-3bb09e5bbdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "word_counts = defaultdict(int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d43531-b2bd-4c0c-aed9-1f349ed70033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {})\n"
     ]
    }
   ],
   "source": [
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1daa328b-90db-4cf2-8a4b-19290b96a6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is  {'join': 8, 'operations': 3, 'are': 2, 'a': 4, 'common': 3, 'type': 1, 'of': 8, 'transformation': 1, 'in': 3, 'big': 1, 'data': 7, 'analytics': 1, 'which': 2, 'two': 2, 'sets,': 1, 'the': 7, 'form': 1, 'tables': 1, 'or': 1, 'dataframes,': 1, 'merged': 1, 'over': 1, 'matching': 1, 'key.': 1, 'similar': 1, 'to': 7, 'relational': 1, 'databases,': 1, 'spark': 5, 'dataframe': 1, 'and': 9, 'dataset': 1, 'apis': 1, 'sql': 1, 'offer': 1, 'series': 1, 'transformations:': 1, 'inner': 1, 'joins,': 4, 'outer': 1, 'left': 1, 'right': 1, 'etc.': 1, 'all': 1, 'these': 3, 'trigger': 1, 'large': 1, 'amount': 1, 'movement': 2, 'across': 2, 'executors.': 1, 'at': 1, 'heart': 1, 'transformations': 1, 'is': 2, 'how': 2, 'computes': 1, 'what': 2, 'produce,': 1, 'keys': 2, 'associated': 1, 'write': 1, 'disk,': 1, 'transfer': 1, 'those': 1, 'nodes': 1, 'as': 2, 'part': 1, 'like': 1, 'groupby(),': 1, 'join(),': 1, 'agg(),': 1, 'sortby(),': 1, 'reducebykey().': 1, 'this': 1, 'commonly': 1, 'referred': 1, 'shuffle.': 1, 'has': 1, 'five': 1, 'distinct': 1, 'strategies': 1, 'by': 1, 'it': 1, 'exchanges,': 1, 'moves,': 1, 'sorts,': 1, 'groups,': 1, 'merges': 1, 'executors:': 1, 'broadcast': 2, 'hash': 2, '(bhj),': 1, 'shuffle': 2, '(shj),': 1, 'sort': 1, 'merge': 1, '(smj),': 1, 'nested': 2, 'loop': 2, '(bnlj),': 1, 'shuffle-and-replicated': 1, '(a.k.a.': 1, 'cartesian': 1, 'product': 1, 'join).': 1, 'we’ll': 1, 'focus': 1, 'on': 1, 'only': 1, 'here': 1, '(bhj': 1, 'smj),': 1, 'because': 1, 'they’re': 1, 'most': 1, 'ones': 1, 'you’ll': 1, 'encounter.': 1}\n",
      " ('and', 9) \n",
      " ('join', 8) \n",
      " ('of', 8) \n",
      " ('data', 7) \n",
      " ('the', 7) \n",
      " ('to', 7) \n",
      " ('spark', 5) \n",
      " ('a', 4) \n",
      " ('joins,', 4) \n",
      " ('operations', 3) \n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "word_counts = defaultdict(int)\n",
    "\n",
    "file_path = \"/Users/rajeshsantha/PycharmProjects/Spark-Programming-In-Python/pythonInterviewQuestions/data/sampletext.txt\"\n",
    "\n",
    "\n",
    "def getWordCount(file_path: str):\n",
    "    try:\n",
    "        for line in open(file_path):\n",
    "            words = line.strip().lower().split()\n",
    "            for word in words:\n",
    "                word_counts[word] += 1\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found - {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    return dict(word_counts)\n",
    "\n",
    "result = getWordCount(file_path)\n",
    "print(\"result is \",result)\n",
    "\n",
    "for word,count in sorted(result.items(),key=lambda x:x[1],reverse=True)[:10]:\n",
    "    print(f\" {word}- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "574eed81-cc7f-4e97-ad03-a168b5948ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'join': 24, 'operations': 9, 'are': 6, 'a': 12, 'common': 9, 'type': 3, 'of': 24, 'transformation': 3, 'in': 9, 'big': 3, 'data': 21, 'analytics': 3, 'which': 6, 'two': 6, 'sets,': 3, 'the': 21, 'form': 3, 'tables': 3, 'or': 3, 'dataframes,': 3, 'merged': 3, 'over': 3, 'matching': 3, 'key.': 3, 'similar': 3, 'to': 21, 'relational': 3, 'databases,': 3, 'spark': 15, 'dataframe': 3, 'and': 27, 'dataset': 3, 'apis': 3, 'sql': 3, 'offer': 3, 'series': 3, 'transformations:': 3, 'inner': 3, 'joins,': 12, 'outer': 3, 'left': 3, 'right': 3, 'etc.': 3, 'all': 3, 'these': 9, 'trigger': 3, 'large': 3, 'amount': 3, 'movement': 6, 'across': 6, 'executors.': 3, 'at': 3, 'heart': 3, 'transformations': 3, 'is': 6, 'how': 6, 'computes': 3, 'what': 6, 'produce,': 3, 'keys': 6, 'associated': 3, 'write': 3, 'disk,': 3, 'transfer': 3, 'those': 3, 'nodes': 3, 'as': 6, 'part': 3, 'like': 3, 'groupby(),': 3, 'join(),': 3, 'agg(),': 3, 'sortby(),': 3, 'reducebykey().': 3, 'this': 3, 'commonly': 3, 'referred': 3, 'shuffle.': 3, 'has': 3, 'five': 3, 'distinct': 3, 'strategies': 3, 'by': 3, 'it': 3, 'exchanges,': 3, 'moves,': 3, 'sorts,': 3, 'groups,': 3, 'merges': 3, 'executors:': 3, 'broadcast': 6, 'hash': 6, '(bhj),': 3, 'shuffle': 6, '(shj),': 3, 'sort': 3, 'merge': 3, '(smj),': 3, 'nested': 6, 'loop': 6, '(bnlj),': 3, 'shuffle-and-replicated': 3, '(a.k.a.': 3, 'cartesian': 3, 'product': 3, 'join).': 3, 'we’ll': 3, 'focus': 3, 'on': 3, 'only': 3, 'here': 3, '(bhj': 3, 'smj),': 3, 'because': 3, 'they’re': 3, 'most': 3, 'ones': 3, 'you’ll': 3, 'encounter.': 3})\n"
     ]
    }
   ],
   "source": [
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c3fee-103d-4f7c-aa6f-bce59d2981c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
