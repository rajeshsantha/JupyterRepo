{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e77f27b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/rajeshsantha/spark351/python (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/anaconda3/lib/python3.12/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2edd7-b3b1-4d8e-a211-cbbba5c2dbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fca7f838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 10:07:17) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e1f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac1732a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 21:42:33 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14764018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   empId    name  supervisor  salary\n",
      "0      3    Brad        <NA>    4000\n",
      "1      1    John           3    1000\n",
      "2      2     Dan           3    2000\n",
      "3      4  Thomas           3    4000\n",
      "   empId  bonus\n",
      "0      2    500\n",
      "1      4   2000\n"
     ]
    }
   ],
   "source": [
    "data = [[3, 'Brad', None, 4000], [1, 'John', 3, 1000], [2, 'Dan', 3, 2000], [4, 'Thomas', 3, 4000]]\n",
    "employee = pd.DataFrame(data, columns=['empId', 'name', 'supervisor', 'salary']).astype(\n",
    "    {'empId': 'Int64', 'name': 'object', 'supervisor': 'Int64', 'salary': 'Int64'})\n",
    "data = [[2, 500], [4, 2000]]\n",
    "bonus = pd.DataFrame(data, columns=['empId', 'bonus']).astype({'empId': 'Int64', 'bonus': 'Int64'})\n",
    "\n",
    "print(employee)\n",
    "print(bonus)\n",
    "\n",
    "empdf = spark.createDataFrame(employee)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f13ef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+------+\n",
      "|empId|name  |supervisor|salary|\n",
      "+-----+------+----------+------+\n",
      "|3    |Brad  |NaN       |4000  |\n",
      "|1    |John  |3.0       |1000  |\n",
      "|2    |Dan   |3.0       |2000  |\n",
      "|4    |Thomas|3.0       |4000  |\n",
      "+-----+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empdf = spark.createDataFrame(employee)\n",
    "empdf.show(10, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3226615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|empId|bonus|\n",
      "+-----+-----+\n",
      "|2    |500  |\n",
      "|4    |2000 |\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bonusdf = spark.createDataFrame(bonus)\n",
    "bonusdf.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46160221-1b25-48f2-bf9c-d010771a9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_survey_df(spark, data_file):\n",
    "    return spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .csv(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5368c68c-fce1-40c6-bd6a-ffe6d9802276",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/rajeshsantha/PycharmProjects/Spark-Programming-In-Python/01-HelloSpark/data/sample.csv\"\n",
    "survey_raw_df = load_survey_df(spark, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29e463ab-57b2-4665-be68-77aed0d42523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------+--------------+-----+-------------+--------------+---------+--------------+--------------+-----------+------------+----------+------------+----------------+----------+----------+------------------+-------------------------+-----------------------+------------+----------+-----------------------+---------------------+------------------+---------------+--------+\n",
      "|          Timestamp|Age|Gender|       Country|state|self_employed|family_history|treatment|work_interfere|  no_employees|remote_work|tech_company|  benefits|care_options|wellness_program| seek_help| anonymity|             leave|mental_health_consequence|phys_health_consequence|   coworkers|supervisor|mental_health_interview|phys_health_interview|mental_vs_physical|obs_consequence|comments|\n",
      "+-------------------+---+------+--------------+-----+-------------+--------------+---------+--------------+--------------+-----------+------------+----------+------------+----------------+----------+----------+------------------+-------------------------+-----------------------+------------+----------+-----------------------+---------------------+------------------+---------------+--------+\n",
      "|2014-08-27 11:29:31| 37|Female| United States|   IL|           NA|            No|      Yes|         Often|          6-25|         No|         Yes|       Yes|    Not sure|              No|       Yes|       Yes|     Somewhat easy|                       No|                     No|Some of them|       Yes|                     No|                Maybe|               Yes|             No|      NA|\n",
      "|2014-08-27 11:29:37| 44|     M| United States|   IN|           NA|            No|       No|        Rarely|More than 1000|         No|          No|Don't know|          No|      Don't know|Don't know|Don't know|        Don't know|                    Maybe|                     No|          No|        No|                     No|                   No|        Don't know|             No|      NA|\n",
      "|2014-08-27 11:29:44| 32|  Male|        Canada|   NA|           NA|            No|       No|        Rarely|          6-25|         No|         Yes|        No|          No|              No|        No|Don't know|Somewhat difficult|                       No|                     No|         Yes|       Yes|                    Yes|                  Yes|                No|             No|      NA|\n",
      "|2014-08-27 11:29:46| 31|  Male|United Kingdom|   NA|           NA|           Yes|      Yes|         Often|        26-100|         No|         Yes|        No|         Yes|              No|        No|        No|Somewhat difficult|                      Yes|                    Yes|Some of them|        No|                  Maybe|                Maybe|                No|            Yes|      NA|\n",
      "|2014-08-27 11:30:22| 31|  Male| United States|   TX|           NA|            No|       No|         Never|       100-500|        Yes|         Yes|       Yes|          No|      Don't know|Don't know|Don't know|        Don't know|                       No|                     No|Some of them|       Yes|                    Yes|                  Yes|        Don't know|             No|      NA|\n",
      "|2014-08-27 11:31:22| 33|  Male| United States|   TN|           NA|           Yes|       No|     Sometimes|          6-25|         No|         Yes|       Yes|    Not sure|              No|Don't know|Don't know|        Don't know|                       No|                     No|         Yes|       Yes|                     No|                Maybe|        Don't know|             No|      NA|\n",
      "|2014-08-27 11:31:50| 35|Female| United States|   MI|           NA|           Yes|      Yes|     Sometimes|           1-5|        Yes|         Yes|        No|          No|              No|        No|        No|Somewhat difficult|                    Maybe|                  Maybe|Some of them|        No|                     No|                   No|        Don't know|             No|      NA|\n",
      "|2014-08-27 11:32:05| 39|     M|        Canada|   NA|           NA|            No|       No|         Never|           1-5|        Yes|         Yes|        No|         Yes|              No|        No|       Yes|        Don't know|                       No|                     No|          No|        No|                     No|                   No|                No|             No|      NA|\n",
      "|2014-08-27 11:32:39| 42|Female| United States|   IL|           NA|           Yes|      Yes|     Sometimes|       100-500|         No|         Yes|       Yes|         Yes|              No|        No|        No|    Very difficult|                    Maybe|                     No|         Yes|       Yes|                     No|                Maybe|                No|             No|      NA|\n",
      "+-------------------+---+------+--------------+-----+-------------+--------------+---------+--------------+--------------+-----------+------------+----------+------------+----------------+----------+----------+------------------+-------------------------+-----------------------+------------+----------+-----------------------+---------------------+------------------+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "survey_raw_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9aa7a7a6-9b4f-4112-a260-854ba7125faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest in /opt/anaconda3/lib/python3.12/site-packages (7.4.4)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/lib/python3.12/site-packages (from pytest) (1.1.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from pytest) (23.2)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/anaconda3/lib/python3.12/site-packages (from pytest) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "306ee7e9-d791-4822-858c-92396a24b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import TestCase\n",
    "from pyspark.sql import SparkSession\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
